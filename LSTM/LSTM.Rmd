---
title: "LSTM 2"
author: "Omair Shafi Ahmed"
date: "11/4/2017"
output: pdf_document
---

```{r}
library('ggplot2')
library('tidyverse')
library('plyr')
library('dplyr')
library('caret')
library('keras')
library('abind')
library('data.table')
```



```{r}
# constants
data_dim <- 16
timesteps <- 8
num_classes <- 10

# define and compile model
# expected input data shape: (batch_size, timesteps, data_dim)
model <- keras_model_sequential() 
model %>% 
  layer_lstm(units = 32, return_sequences = TRUE, input_shape = c(timesteps, data_dim)) %>% 
  layer_lstm(units = 32, return_sequences = TRUE) %>% 
  layer_lstm(units = 32) %>% # return a single vector dimension 32
  layer_dense(units = 10, activation = 'softmax') %>% 
  compile(
    loss = 'categorical_crossentropy',
    optimizer = 'rmsprop',
    metrics = c('accuracy')
  )
  
# generate dummy training data
x_train <- array(runif(1000 * timesteps * data_dim), dim = c(1000, timesteps, data_dim))
y_train <- matrix(runif(1000 * num_classes), nrow = 1000, ncol = num_classes)

# generate dummy validation data
x_val <-array(runif(100 * timesteps * data_dim), dim = c(100, timesteps, data_dim))
y_val <- matrix(runif(100 * num_classes), nrow = 100, ncol = num_classes)

# train
model %>% fit( 
  x_train, y_train, batch_size = 64, epochs = 5, validation_data = list(x_val, y_val)
)

```


```{r}

prices <- read_csv('/Users/omairs/Documents/Masters/DS 5110/HW2/data/nyse/prices-split-adjusted.csv')

#abind(rbind(temp[['low']], temp[['high']]), rbind(temp[['low']], temp[['high']]), along=3)

#Required 501*1762*4
temp  <- matrix(ncol = 251) 
temp_2 <- array(dim=c(502,1762,1))
counter <- 1

for (ohlc in c('open', 'high', 'low', 'close')){

    temp  <- matrix(ncol = 501)
    
    
    for (i in 1:length(unique(prices$symbol))){
      
          #select the stock + ohlc from the main df
          temp_1    <- prices %>% filter(`symbol` == unique(prices$symbol)[i]) %>%
                        select(ohlc)
          
          #formatting
          temp_1    <- t(as.matrix(temp_1))
          
          #attaching to the main df
          temp      <- rbind.fill.matrix(temp, temp_1)
          
    }
  
 
    if (counter == 1){
    
      #create new matrix of the same dim if the loop runs for the first time
      temp2 <- matrix(nrow = dim(temp)[1], ncol = dim(temp)[2])
      counter <- 0
  
    }
  
  
    temp_2 <- abind(temp_2, temp, along = 3)
  
}

temp_2 <- temp_2[,,2:5]

```





```{r}


#pre_process <- prices %>% filter(`symbol` == "AAPL") %>% as.data.frame %>%                 preProcess(prices[,3:7], method=c("scale"))

#transformed <- predict(pre_process, prices[,3:7])

#summary(transformed)

#data_dim <- ncol(transformed)
#timesteps <- nrow(transformed)

model <- keras_model_sequential() 
model %>% 
  layer_lstm(units = 32, return_sequences = TRUE, input_shape =  c(dim(temp_2)[2], dim(temp_2)[3])) %>% 
  layer_lstm(units = 32, return_sequences = TRUE) %>% 
  layer_lstm(units = 32) %>% # return a single vector dimension 32
  layer_dense(units = 10, activation = 'softmax') %>% 
  compile(
    loss = 'categorical_crossentropy',
    optimizer = 'rmsprop',
    metrics = c('accuracy')
  )
  
x_train <- temp_2
y_train <- matrix(runif(502 * 10), nrow = 502, ncol = 10)

# generate dummy validation data
x_val <- temp_2
y_val <- matrix(runif(502 * 10), nrow = 502, ncol = 10)

# train
model %>% fit( 
  x_train, y_train, batch_size = 64, epochs = 5, validation_data = list(x_val, y_val)
)


```







#RUN1

##Read data and filter appropraite data

```{r}

ohlc = "close"
lookback = 3


prices <- read_csv('/Users/omairs/Documents/Masters/DS 5110/HW2/data/nyse/prices-split-adjusted.csv')
aapl_close <- prices %>% filter(`symbol` == "AAPL") %>% select(`close`)
aapl_open <- prices %>% filter(`symbol` == "AAPL") %>% select(`open`)

```

## Shift and wrangle as needed
```{r}


create_horizontal_timeseries <- function(data_frame, col_name, time_steps){
  
  test <- list()
  for (i in 1:time_steps) {
    
      shifted <- shift(data_frame[,col_name], (i), fill=NA)
      test <- c(test, shifted)
      #data_frame3 <- cbind(data_frame2, as.data.frame(shifted))
      data_frame[paste(col_name, i)] <- test[[i]]
    
    }
  
  data_frame <- na.omit(data_frame)

  data_frame <- apply(data_frame, 2, function(x)(x-min(x))/(max(x)-min(x)))
  
  data_frame
}


stock_vector_close <- create_horizontal_timeseries(aapl_close, "close", 3)
stock_vector_open <- create_horizontal_timeseries(aapl_open, "open", 3)

```


Split into Train and Test

```{r}


create_cross_validation <- function(stock_vector){
  

    train_y <- stock_vector[1:as.numeric(0.67*nrow(stock_vector)),ncol(stock_vector)]
    test_y  <- stock_vector[(0.67*nrow(stock_vector)):nrow(stock_vector),
                              ncol(stock_vector)]
    
    train_x   <- stock_vector[1:as.numeric(0.67*nrow(stock_vector)),1:(ncol(stock_vector)-1)]
    test_x    <- stock_vector[as.numeric(0.67*nrow(stock_vector)):nrow(stock_vector),
                                          1:(ncol(stock_vector)-1)]
    
    #abind(aapl_train, matrix(nrow = nrow(aapl_train), ncol = ncol(aapl_train)), along = 3)
    
    list(train_y, test_y, train_x, test_x)
    
}

create_cross_validation_output_close <- create_cross_validation(stock_vector_close)
create_cross_validation_output_open <- create_cross_validation(stock_vector_open)

train_y <- create_cross_validation_output_close[[1]]
test_y  <- create_cross_validation_output_close[[2]]

close_train_x <- create_cross_validation_output_close[[3]]
close_test_x  <- create_cross_validation_output_close[[4]]

open_train_x <- create_cross_validation_output_open[[3]]
open_test_x  <- create_cross_validation_output_open[[4]]


train_x <- abind(open_train_x, close_train_x, along=3)
test_x <- abind(open_test_x, close_test_x, along=3)
```


Create an LSTM

```{r}
model <- keras_model_sequential() 
model %>% layer_lstm (units = 8, return_sequences = TRUE, input_shape = c(3, 2)) %>%
                        layer_flatten %>%
                        layer_dense(units = 1, activation = 'sigmoid') %>% 
                        compile(
                            loss = 'mean_squared_error',
                            optimizer = 'adam',
                            metrics = c('accuracy')
                            )
  
model %>% fit(train_x, train_y, batch_size = 10, epochs = 100, validation_data = list(test_x, test_y)
)

```



#Predict and Undo Scaling

```{r}

scaled_predictions       <- as.data.frame(predict(model, test_x))
scaled_predictions$epoch <- as.numeric(row.names(as.data.frame(predict(model, test_x))))

actual_values           <- as.data.frame(test_y)
actual_values$epoch     <- as.numeric(row.names(actual_values))

scaled_predictions %>% ggplot() + geom_line(aes(y=`V1`, x=`epoch`), color='blue') +
                                  geom_line(aes(y=`test_y`, x=`epoch`), color='red')


predictions <- as.data.frame(apply(as.data.frame(predict(model, test_x)), MARGIN = 2, FUN = function(x)
                                ((x * (max(aapl_close) - min(aapl_close))) + min(aapl_close))))


predictions$actual <- apply(as.data.frame(test_y), MARGIN = 2, FUN = function(x)
                            ((x * (max(aapl_close) - min(aapl_close))) + min(aapl_close)))

predictions$epoch <- as.numeric(row.names(predictions))

names(predictions)[names(predictions) == 'V1'] <- "predicted"

predictions %>% ggplot() + geom_line(aes(y=`predicted`, x=`epoch`), color='blue') +
                                  geom_line(aes(y=`actual`, x=`epoch`), color='red') +
                                  ylab('Price')

```


##Calculating Residuals
```{r}

predictions$residuals <- as.numeric(predictions$actual - predictions$predicted)

rmse <- sqrt(mean(predictions$residuals^2))

r_squared <- cor(predictions$actual, predictions$predicted) ^ 2

predictions$accuracy <- as.numeric(predictions$residual/predictions$actual*100)

head(predictions)

cor(predictions$actual, predictions$predicted) ^ 2

```

